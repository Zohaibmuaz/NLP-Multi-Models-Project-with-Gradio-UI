# -*- coding: utf-8 -*-
"""AI NLP Assistant Multi-Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-MAYNh8I3Hi1m74-6pSCTgOBaWP95ZG3
"""

import gradio as gr
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch

# Load the Qwen model
model_name = "Qwen/Qwen2-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# Other pipelines
sentiment = pipeline("sentiment-analysis")
generator = pipeline("text-generation", model="gpt2")
ner_model = pipeline("ner", grouped_entities=True)
qa = pipeline("question-answering")

# ChatBot Response Function
def chat_with_bot(user_input, history=[]):
    messages = [{"role": "user", "content": user_input}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)
    generated_ids = [
        output_ids[len(input_ids):]
        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response

# Other feature functions
def do_sentiment(text):
    result = sentiment(text)[0]
    return f"Label: {result['label']}, Score: {result['score']:.2f}"

def generate_text(prompt):
    result = generator(prompt, max_length=100, num_return_sequences=1)
    return result[0]['generated_text']

def named_entities(text):
    result = ner_model(text)
    return "\n".join(f"{e['word']} ({e['entity_group']}) - {e['score']:.2f}" for e in result)

def answer_question(question, context):
    result = qa(question=question, context=context)
    return result["answer"]

# UI Tabs
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("üåü AI NLP Assistant ‚Äì Powered by Transformers")

    with gr.Tab("üí¨ ChatBot"):
        chatbot = gr.ChatInterface(fn=chat_with_bot)

    with gr.Tab("üß† Sentiment Analysis"):
        text = gr.Textbox(label="Enter text")
        sent_btn = gr.Button("Analyze")
        sent_output = gr.Textbox(label="Result")
        sent_btn.click(do_sentiment, inputs=text, outputs=sent_output)

    with gr.Tab("‚úçÔ∏è Text Generation"):
        prompt = gr.Textbox(label="Enter prompt")
        gen_btn = gr.Button("Generate Text")
        gen_output = gr.Textbox(label="Generated")
        gen_btn.click(generate_text, inputs=prompt, outputs=gen_output)

    with gr.Tab("üîç Named Entity Recognition"):
        ner_input = gr.Textbox(label="Enter text")
        ner_btn = gr.Button("Find Entities")
        ner_output = gr.Textbox(label="Entities Found")
        ner_btn.click(named_entities, inputs=ner_input, outputs=ner_output)

    with gr.Tab("‚ùì Question Answering"):
        q = gr.Textbox(label="Question")
        ctx = gr.Textbox(label="Context")
        ans_btn = gr.Button("Get Answer")
        ans_output = gr.Textbox(label="Answer")
        ans_btn.click(answer_question, inputs=[q, ctx], outputs=ans_output)

demo.launch()

